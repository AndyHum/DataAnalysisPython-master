{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import oauth2 as oauth\n",
    "import json,requests\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "import matplotlib.pyplot\n",
    "import pylab\n",
    "import numpy as np #just for a random color not used to analyze data\n",
    "\n",
    "\n",
    "CONSUMER_KEY = \"WC3zaJa2gSa8A8UkFRCn9YWvO\"\n",
    "CONSUMER_SECRET = \"3So1Ld1muwpE2Pwt8nShw0iQL6jialgiNCtnxiiCaH5tHh4ESi\"\n",
    "ACCESS_KEY = \"570787998-19TdCbxP2ES2IMqszhBhylnbuqqYdrwuCTXvdXp4\"\n",
    "ACCESS_SECRET = \"jchylHmi980oWVjPumMo5Dp20oR8vF522hnGnKqquOVap\"\n",
    "\n",
    "consumer = oauth.Consumer(key=CONSUMER_KEY, secret=CONSUMER_SECRET)\n",
    "access_token = oauth.Token(key=ACCESS_KEY, secret=ACCESS_SECRET)\n",
    "client = oauth.Client(consumer, access_token)\n",
    "\n",
    "term_0 = input(\"What do you want to search?\")\n",
    "#datetime用来分析的时候 获取当前时间 命名文件夹？或者用来规范搜索时输入的时间选项？\n",
    "#datetime_now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "# p = ArgumentParser(usage='it is usage tip', description='this is a test')\n",
    "# #根据twitter api搜索词转换规则 转换\n",
    "# p.add_argument('--trump clinton', default='trump%20clinton', help='the first argument')\n",
    "# p.add_argument('--two', default=2, type=int, help='the second argument')\n",
    "# p.add_argument('--docs-dir', default=\"./\", help='document directory ')\n",
    "# args = p.parse_args()\n",
    "#term_1 = args.term_0\n",
    "\n",
    "count = input(\"How many data do you want?\")\n",
    "\n",
    "date_0 = input(\"What date do you want to set?:\")\n",
    "#date_1 = datetime.date(date_0).isoformat()\n",
    "\n",
    "#location = input(\"Tweets from where do you want to see?:\")\n",
    "\n",
    "choose_time = int(input(\"What kind of date do you want to set? Input 1 means since date, input 2 means up to date.:\"))\n",
    "\n",
    "\n",
    "if choose_time==1:\n",
    "    #global search_1\n",
    "    integra_search = \"%20since%3A\" + date_0 + '&count=' + count\n",
    "    search_1 = \"https://api.twitter.com/1.1/search/tweets.json?q=\" + term_0 + integra_search\n",
    "if choose_time==2:\n",
    "    #global search_1\n",
    "    integra_search = \"%20until%3A\" + date_0 + '&count=' + count\n",
    "    search_1 = \"https://api.twitter.com/1.1/search/tweets.json?q=\" + term_0 + integra_search\n",
    "else:\n",
    "    search_1 = \"https://api.twitter.com/1.1/search/tweets.json?q=\" + term_0 + \"%20until%3A\" + date_0 + '&count=' + count\n",
    "    print(\"Your input is wrong, please input again\")\n",
    "    #Should be a recursive function?\n",
    "\n",
    "response, data = client.request(search_1)\n",
    "\n",
    "str_response = data.decode('utf-8')\n",
    "tweets = json.loads(str_response)\n",
    "\n",
    "#function to check if folder is present if not create it\n",
    "def Save_Json():\n",
    "    path = input(\"Please input a path to save data:\")\n",
    "    def check_folder():\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    check_folder()\n",
    "    #Save tweets data in json\n",
    "    json.dump(tweets, open(path + '\\\\' + term_0 + '.dat', 'w'))\n",
    "\n",
    "#Analysis one: What is the average number of friends do users have?\n",
    "def Analysis_One():\n",
    "    print(type(str_response))\n",
    "    friends_sum = 0\n",
    "    for i in range(int(count)):\n",
    "        jsonData = tweets[\"statuses\"][i][\"user\"]\n",
    "    # print(tweets[\"statuses\"][0][\"user\"].keys())\n",
    "    # for item in jsonData:\n",
    "        friends_count = jsonData[\"friends_count\"]\n",
    "        id = jsonData[\"id\"]\n",
    "        friends_sum += int(friends_count)\n",
    "        print(\"User id is: {}\".format(id), \"  User friends_count is: {}\".format(friends_count))\n",
    "    friends_avg = friends_sum/int(count)\n",
    "    print(\"Users' average friends count is: {}\".format(friends_avg))\n",
    "\n",
    "# #Analysis two: States; Find mode\n",
    "\n",
    "def Analysis_Two():\n",
    "    dic = {'Foreign': '0', 'Alien': '0', 'Alabama': '0', 'Alaska': '0', 'American Samoa': '0', 'Arizona': '0',\n",
    "           'Arkansas': '0', 'California': '0', 'Colorado': '0', 'Connecticut': '0', 'Delaware': '0',\n",
    "           'Washington, D.C.': '0', 'Florida': '0', 'Georgia': '0', 'Guam': '0', 'Hawaii': '0', 'Idaho': '0',\n",
    "           'Illinois': '0', 'Indiana': '0', 'Kansas': '0', 'Iowa': '0', 'Kentucky': '0', 'Louisiana': '0', 'Maine': '0',\n",
    "           'Maryland': '0', 'Marshall Islands': '0', 'Massachusetts': '0', 'Michigan': '0', 'Micronesia': '0',\n",
    "           'Minnesota': '0', 'Mississippi': '0', 'Montana': '0', 'Nebraska': '0', 'Nevada': '0', 'New Hampshire': '0',\n",
    "           'New Jersey': '0', 'New Mexico': '0', 'New York': '0', 'North Carolina': '0', 'North Dakota': '0',\n",
    "           'Northern Marianas': '0', 'Ohio': '0', 'Oklahoma': '0', 'Oregon': '0', 'Palau': '0', 'Pennsylvania': '0',\n",
    "           'Puerto Rico': '0', 'Rhode Island': '0', 'Missouri': '0', 'South Carolina': '0', 'South Dakota': '0',\n",
    "           'Tennessee': '0', 'Texas': '0', 'Utah': '0', 'Vermont': '0', 'Virginia': '0', 'Virgin Islands': '0',\n",
    "           'Washington': '0', 'West Virginia': '0', 'Wisconsin': '0', 'Wyoming': '0'}\n",
    "    dic = dic.fromkeys(dic.keys(), 0)\n",
    "\n",
    "    for i in range(int(count) - 1):\n",
    "        jsonData = tweets[\"statuses\"][i][\"user\"]\n",
    "        user_location = jsonData[\"location\"]\n",
    "        id = jsonData[\"id\"]\n",
    "\n",
    "        url = \"http://api.geonames.org/searchJSON?formatted=true&q=\" + user_location + \"&maxRows=10&lang=en&username=limuzi0609&style=full\"\n",
    "        data = json.dumps({\"name\": \"test_repo\", \"description\": \"test\"})\n",
    "        r = requests.post(url, data)\n",
    "        print(user_location)\n",
    "        if r.json()[\"totalResultsCount\"] == 0:\n",
    "            dic['Alien'] += 1\n",
    "        elif r.json()[\"geonames\"][0][\"countryCode\"] == \"US\" and r.json()[\"geonames\"][0][\"adminName1\"] is not '':\n",
    "            state = r.json()[\"geonames\"][0][\"adminName1\"]\n",
    "            dic[state] += 1\n",
    "        else:\n",
    "            dic['Foreign'] += 1\n",
    "\n",
    "    dic = {k: v for (k, v) in dic.items() if v > 0}\n",
    "    print(dic.items())\n",
    "    # visualisation\n",
    "    wordlist=[]\n",
    "    for key,val in dic.items():\n",
    "        wordlist.append((key,val))\n",
    "    matplotlib.pyplot.figure(figsize=(9, 6))\n",
    "    wordlist.sort()\n",
    "    keylist=[key for key,val in wordlist]\n",
    "    vallist=[val for key,val in wordlist]\n",
    "    barwidth=0.3\n",
    "    xVal=np.arange(len(keylist))\n",
    "    pylab.xticks(xVal+barwidth/2.0,keylist,rotation=45)\n",
    "    pylab.bar(xVal,vallist,width=barwidth,color='lightskyblue',edgecolor = 'white')\n",
    "\n",
    "    pylab.title(u\"Bar Chart of Users' States\" )\n",
    "    pylab.show()\n",
    "\n",
    "    # print(\"User id is: {}\".format(id), \"  User location is: \" + user_location)\n",
    "# print(tweets)\n",
    "\n",
    "# Analysis Three: Relationship between retweets and followers number\n",
    "\n",
    "def Analysis_Three():\n",
    "    matplotlib.pyplot.figure(figsize=(9,6))\n",
    "\n",
    "    followers_num = []\n",
    "    retweet_num = []\n",
    "\n",
    "    for i in range(int(count)):\n",
    "        followers_count = tweets[\"statuses\"][i][\"user\"][\"followers_count\"]\n",
    "        retweet_count = tweets[\"statuses\"][i][\"retweet_count\"]\n",
    "        followers_num.append(followers_count)\n",
    "        retweet_num.append(retweet_count)\n",
    "        print(\"Tweets retweet number is: {}\".format(retweet_count), \" User's followers number is: {}\".format(followers_count))\n",
    "\n",
    "    T = np.arctan2(followers_num,retweet_num)\n",
    "    matplotlib.pyplot.scatter(followers_num,retweet_num,c=T,s=25,alpha=0.4,marker='o')\n",
    "    matplotlib.pyplot.xlabel(\"User's follower number\")\n",
    "    matplotlib.pyplot.ylabel(\"User's this tweet's retweet number\")\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "# Analysis Four: Average mention users' number\n",
    "def Analysis_Four():\n",
    "    user_mentioned = 0\n",
    "    for i in range(int(count)):\n",
    "        mentioned_count = len(tweets[\"statuses\"][i][\"entities\"][\"user_mentions\"])\n",
    "        id = tweets[\"statuses\"][i][\"user\"][\"id\"]\n",
    "        user_mentioned += mentioned_count\n",
    "        print(\"User id is: {}\".format(id), \"  User mentioned people number is: {}\".format(mentioned_count))\n",
    "    mentioned_avg = user_mentioned/int(count)\n",
    "    print(\"Users' average friends count is: {}\".format(mentioned_avg))\n",
    "\n",
    "# Analysis Five: Average mention users' number\n",
    "def Analysis_Five():\n",
    "    term_1 = input(\"What do you want to search?\")\n",
    "    if choose_time == 1:\n",
    "        # global search_1\n",
    "        integra_search = \"%20since%3A\" + date_0 + '&count=' + count\n",
    "        search_2 = \"https://api.twitter.com/1.1/search/tweets.json?q=\" + term_1 + integra_search\n",
    "    if choose_time == 2:\n",
    "        # global search_1\n",
    "        integra_search = \"%20until%3A\" + date_0 + '&count=' + count\n",
    "        search_2 = \"https://api.twitter.com/1.1/search/tweets.json?q=\" + term_1 + integra_search\n",
    "    else:\n",
    "        search_2 = \"https://api.twitter.com/1.1/search/tweets.json?q=\" + term_1 + \"%20until%3A\" + date_0 + '&count=' + count\n",
    "        print(\"Your input is wrong, please input again\")\n",
    "\n",
    "    response_1, data_1 = client.request(search_2)\n",
    "\n",
    "    str_response_1 = data_1.decode('utf-8')\n",
    "    tweets_1 = json.loads(str_response_1)\n",
    "\n",
    "    dic = {'Foreign': '0', 'Alien': '0', 'Alabama': '0', 'Alaska': '0', 'American Samoa': '0', 'Arizona': '0',\n",
    "           'Arkansas': '0', 'California': '0', 'Colorado': '0', 'Connecticut': '0', 'Delaware': '0',\n",
    "           'Washington, D.C.': '0', 'Florida': '0', 'Georgia': '0', 'Guam': '0', 'Hawaii': '0', 'Idaho': '0',\n",
    "           'Illinois': '0', 'Indiana': '0', 'Kansas': '0', 'Iowa': '0', 'Kentucky': '0', 'Louisiana': '0', 'Maine': '0',\n",
    "           'Maryland': '0', 'Marshall Islands': '0', 'Massachusetts': '0', 'Michigan': '0', 'Micronesia': '0',\n",
    "           'Minnesota': '0', 'Mississippi': '0', 'Montana': '0', 'Nebraska': '0', 'Nevada': '0', 'New Hampshire': '0',\n",
    "           'New Jersey': '0', 'New Mexico': '0', 'New York': '0', 'North Carolina': '0', 'North Dakota': '0',\n",
    "           'Northern Marianas': '0', 'Ohio': '0', 'Oklahoma': '0', 'Oregon': '0', 'Palau': '0', 'Pennsylvania': '0',\n",
    "           'Puerto Rico': '0', 'Rhode Island': '0', 'Missouri': '0', 'South Carolina': '0', 'South Dakota': '0',\n",
    "           'Tennessee': '0', 'Texas': '0', 'Utah': '0', 'Vermont': '0', 'Virginia': '0', 'Virgin Islands': '0',\n",
    "           'Washington': '0', 'West Virginia': '0', 'Wisconsin': '0', 'Wyoming': '0'}\n",
    "    dic_1 = {'Foreign': '0', 'Alien': '0', 'Alabama': '0', 'Alaska': '0', 'American Samoa': '0', 'Arizona': '0',\n",
    "           'Arkansas': '0', 'California': '0', 'Colorado': '0', 'Connecticut': '0', 'Delaware': '0',\n",
    "           'Washington, D.C.': '0', 'Florida': '0', 'Georgia': '0', 'Guam': '0', 'Hawaii': '0', 'Idaho': '0',\n",
    "           'Illinois': '0', 'Indiana': '0', 'Kansas': '0', 'Iowa': '0', 'Kentucky': '0', 'Louisiana': '0', 'Maine': '0',\n",
    "           'Maryland': '0', 'Marshall Islands': '0', 'Massachusetts': '0', 'Michigan': '0', 'Micronesia': '0',\n",
    "           'Minnesota': '0', 'Mississippi': '0', 'Montana': '0', 'Nebraska': '0', 'Nevada': '0', 'New Hampshire': '0',\n",
    "           'New Jersey': '0', 'New Mexico': '0', 'New York': '0', 'North Carolina': '0', 'North Dakota': '0',\n",
    "           'Northern Marianas': '0', 'Ohio': '0', 'Oklahoma': '0', 'Oregon': '0', 'Palau': '0', 'Pennsylvania': '0',\n",
    "           'Puerto Rico': '0', 'Rhode Island': '0', 'Missouri': '0', 'South Carolina': '0', 'South Dakota': '0',\n",
    "           'Tennessee': '0', 'Texas': '0', 'Utah': '0', 'Vermont': '0', 'Virginia': '0', 'Virgin Islands': '0',\n",
    "           'Washington': '0', 'West Virginia': '0', 'Wisconsin': '0', 'Wyoming': '0'}\n",
    "    dic = dic.fromkeys(dic.keys(), 0)\n",
    "    dic_1 = dic_1.fromkeys(dic_1.keys(), 0)\n",
    "\n",
    "    for i in range(int(count) - 1):\n",
    "        jsonData = tweets[\"statuses\"][i][\"user\"]\n",
    "        jsonData_1 = tweets_1[\"statuses\"][i][\"user\"]\n",
    "        user_location = jsonData[\"location\"]\n",
    "        user_location_1 = jsonData_1[\"location\"]\n",
    "        id = jsonData[\"id\"]\n",
    "        id_1 = jsonData_1[\"id\"]\n",
    "\n",
    "        url = \"http://api.geonames.org/searchJSON?formatted=true&q=\" + user_location + \"&maxRows=10&lang=en&username=limuzi0609&style=full\"\n",
    "        url_1 = \"http://api.geonames.org/searchJSON?formatted=true&q=\" + user_location_1 + \"&maxRows=10&lang=en&username=limuzi0609&style=full\"\n",
    "        data = json.dumps({\"name\": \"test_repo\", \"description\": \"test\"})\n",
    "        data_1 = json.dumps({\"name\": \"test_repo\", \"description\": \"test\"})\n",
    "        r = requests.post(url, data)\n",
    "        r_1 = requests.post(url_1, data_1)\n",
    "        print(user_location)\n",
    "        print(user_location_1)\n",
    "        if r.json()[\"totalResultsCount\"] == 0:\n",
    "            dic['Alien'] += 1\n",
    "        elif r.json()[\"geonames\"][0][\"countryCode\"] == \"US\" and r.json()[\"geonames\"][0][\"adminName1\"] is not '':\n",
    "            state = r.json()[\"geonames\"][0][\"adminName1\"]\n",
    "            dic[state] += 1\n",
    "        else:\n",
    "            dic['Foreign'] += 1\n",
    "\n",
    "        if r_1.json()[\"totalResultsCount\"] == 0:\n",
    "            dic_1['Alien'] += 1\n",
    "        elif r_1.json()[\"geonames\"][0][\"countryCode\"] == \"US\" and r_1.json()[\"geonames\"][0][\"adminName1\"] is not '':\n",
    "            state_1 = r_1.json()[\"geonames\"][0][\"adminName1\"]\n",
    "            dic_1[state_1] += 1\n",
    "        else:\n",
    "            dic_1['Foreign'] += 1\n",
    "\n",
    "    #dic = {k: v for (k, v) in dic.items() if v > 0}\n",
    "    print(dic.items())\n",
    "    #dic_1 = {k: v for (k, v) in dic_1.items() if v > 0}\n",
    "    print(dic_1.items())\n",
    "    # visualisation\n",
    "    wordlist = []\n",
    "    wordlist_1 = []\n",
    "    for key, val in dic.items():\n",
    "        wordlist.append((key, val))\n",
    "    matplotlib.pyplot.figure(figsize=(9, 6))\n",
    "    wordlist.sort()\n",
    "    keylist = [key for key, val in wordlist]\n",
    "    vallist = [val for key, val in wordlist]\n",
    "\n",
    "    for key_1, val_1 in dic_1.items():\n",
    "        wordlist_1.append((key_1, val_1))\n",
    "    wordlist_1.sort()\n",
    "    keylist_1 = [key_1 for key_1, val_1 in wordlist_1]\n",
    "    vallist_1 = [val_1 for key_1, val_1 in wordlist_1]\n",
    "\n",
    "    barwidth = 0.35\n",
    "    xVal = np.arange(len(keylist))+1\n",
    "    pylab.xticks((xVal*2 + barwidth) / 2.0, keylist, rotation=45)\n",
    "    pylab.bar(xVal, vallist, width=barwidth, color='lightskyblue', edgecolor='white')\n",
    "    pylab.bar(xVal+0.35, vallist_1, width=barwidth, color='yellowgreen', edgecolor='white')\n",
    "\n",
    "    pylab.title(u\"Lightskyblue for Trump, Yellowgreen for Clinton\")\n",
    "    pylab.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Save_Json()\n",
    "    Analysis_One()\n",
    "    Analysis_Two()\n",
    "    Analysis_Three()\n",
    "    Analysis_Four()\n",
    "    Analysis_Five()\n",
    "\n",
    "    parser = ArgumentParser(description='Process some integers.')\n",
    "    parser.add_argument('--1', default=Analysis_One(), help='Analysis 1')\n",
    "    parser.add_argument('--2', default=Analysis_Two(), help='Analysis 2')\n",
    "    parser.add_argument('--3', default=Analysis_Three(), help='Analysis 3')\n",
    "    parser.add_argument('--4', default=Analysis_Four(), help='Analysis 4')\n",
    "    parser.add_argument('--5', default=Analysis_Five(), help='Analysis 5')\n",
    "    args = parser.parse_args()\n",
    "    print(args.accumulate(args.integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
